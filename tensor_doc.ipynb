{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joey2441-spec/The-C-Programming-Language-2nd-Edition/blob/master/tensor_doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OwpjIKO9qiv"
      },
      "source": [
        "Creating tensors, mathematical ops, reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9sDRuSBqUXM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Initialization of Tensors\n",
        "x = tf.constant(4, shape=(1,1), dtype=tf.float32)\n",
        "x = tf.constant([[1,2,3], [4,5,6]])\n",
        "x = tf.ones((2,3))\n",
        "x = tf.zeros((3,3))\n",
        "x = tf.eye(3, dtype=tf.int32) # identity matrix 3x3\n",
        "x = tf.random.normal((3,3,4), mean=0, stddev=1) # a distribution\n",
        "x = tf.random.uniform((1,3), minval=0, maxval=1) # a uniform distribution\n",
        "x = tf.range(9)\n",
        "x = tf.range(start=1, limit=10, delta=2) # similar to python range\n",
        "x = tf.cast(x, dtype=tf.float64) # tf.float(16,32,64), tf.int(8,16,32,64), tf.bool\n",
        "\n",
        "#print(type(x))\n",
        "#print(x)\n",
        "\n",
        "# Mathematical Operations\n",
        "x = tf.constant([1,2,3])\n",
        "y = tf.constant([9,8,7])\n",
        "\n",
        "z = tf.add(x, y) # an element wise addition\n",
        "z = x + y # overloaded addition\n",
        "\n",
        "z = tf.subtract(x, y)\n",
        "z = x - y\n",
        "\n",
        "z = tf.multiply(x, y) # element wise multiplication\n",
        "z = tf.divide(x, y)\n",
        "\n",
        "z = tf.tensordot(x, y, axes=1) # element wise multiplication then addition\n",
        "z = tf.reduce_sum(x * y, axis=0)\n",
        "\n",
        "z = x ** 3 # element wise exponent\n",
        "\n",
        "x = tf.random.normal((2,3))\n",
        "y = tf.random.normal((3,4))\n",
        "z = tf.matmul(x,y)\n",
        "z = x @ y # same as matmul\n",
        "\n",
        "#print(z)\n",
        "\n",
        "# Indexing\n",
        "x = tf.constant([0,1,2,3,4,4,2,3])\n",
        "\n",
        "\"\"\"\n",
        "print(x[:])\n",
        "print(x[1:])\n",
        "print(x[1:3]) # [start:end] start is inclusive but end is not\n",
        "print(x[::2]) # [start::step]\n",
        "print(x[::-1]) # reverse order\n",
        "\"\"\"\n",
        "\n",
        "indices=tf.constant([0,5]) # just a list\n",
        "x_ind = tf.gather(x, indices) # get elements in the indexes of x\n",
        "\n",
        "#print(x_ind)\n",
        "\n",
        "x = tf.constant([[1,2],[3,4],[5,6],[7,8]]) # (4,2)\n",
        "\"\"\"\n",
        "print(x[0,1]) # seperate dimensions by comma, give me first element and the second element of it\n",
        "print(x[0:2,:])\n",
        "\"\"\"\n",
        "\n",
        "# Reshaping\n",
        "x = tf.range(9)\n",
        "\n",
        "print(x)\n",
        "x = tf.reshape(x, (3,3))\n",
        "\n",
        "print(tf.transpose(x, perm=[1,0])) # make the rows to col\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJaxd6Ql9z-q"
      },
      "source": [
        "1.) Neural Networks with Sequential and Keras API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb9frsEf96OR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# x_train.shape=(60000,28,28) y_train.shape=(60000,)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0 # normalizes data to 0<=x<=1\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
        "\n",
        "# Sequential API (very convenient, not flexible) one input to one output\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10),\n",
        "])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # from_logits does a softmax\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy'], # keep track of running accuracy\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n",
        "\n",
        "print(type(x_train))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.)Char RNN"
      ],
      "metadata": {
        "id": "2JhrrlPEmWIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load ASCII text and convert to lowercase\n",
        "filename = “wonderland.txt”\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "# create a mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars — seq_length, 1):\n",
        "seq_in = raw_text[i:i + seq_length]\n",
        "seq_out = raw_text[i + seq_length]\n",
        "dataX.append([char_to_int[char] for char in seq_in])\n",
        "dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(“Total Patterns: “, n_patterns)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation=’softmax’))\n",
        "model.compile(loss=’categorical_crossentropy’, optimizer=’adam’)\n",
        "model.summary()\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(start,len(pattern))\n",
        "print (“Seed:”)\n",
        "print (‘’.join([int_to_char[value] for value in pattern]))\n",
        "\n",
        "#import sys\n",
        "# generate characters\n",
        "for i in range(500):\n",
        " x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        " x = x / float(n_vocab)\n",
        " prediction = model.predict(x, verbose=0)\n",
        " index = numpy.argmax(prediction)\n",
        " result = int_to_char[index]\n",
        " seq_in = [int_to_char[value] for value in pattern]\n",
        " #sys.stdout.write(result)\n",
        " print(result,end=””)\n",
        " if i%100 == 0 and i != 0:\n",
        " print(“\\n”)\n",
        " pattern.append(index)\n",
        " pattern = pattern[1:len(pattern)]\n",
        "print (“\\nDone.”)"
      ],
      "metadata": {
        "id": "O8LgvFKVmV7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.)Convolutional Neural Network"
      ],
      "metadata": {
        "id": "QTAdJ7qZieWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, 3, padding=\"valid\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(128, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = my_model()\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "id": "ld2chaK6iiY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.)Regularization with L2 and Dropout"
      ],
      "metadata": {
        "id": "KErY86u-tJrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, 3, padding=\"valid\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(128, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = my_model()\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "id": "PzL12BpstJhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.) Regularization to prevent overfitting (L2, Dropout, Early stoppage, Data augmentation)"
      ],
      "metadata": {
        "id": "mmHCLAJT6UaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, 3, padding=\"valid\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(0.5)(x) # drop 0.5 connections between Dense(64) and Dense(10) to help prevent overfitting\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = my_model()\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=150, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "id": "85cLkZjq6gf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.) RNNs, GRUs, LSTMs"
      ],
      "metadata": {
        "id": "_eXx9C3YDk9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# image of 28x28 pixels\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0 # normalize data\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# each time step unroll one row of image at a time\n",
        "# timestep 1 takes the first row\n",
        "# timestep 2 takes the second row\n",
        "# In general you wouldn't use sequence models like RNNs instead you would use Convolutional\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28))) # None because we don't have a specified number of time steps (arbitrary)\n",
        "model.add(layers.SimpleRNN(256, return_sequences=True, activation='tanh')) # output of this is 512 nodes and outputs it\n",
        "model.add(layers.SimpleRNN(256, activation='tanh'))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
        "print(model.summary())\n",
        "print(x_train.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "hGq920VLDk0l",
        "outputId": "8be02dda-c4fe-49d2-a72c-13fa93b125e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b70226cae3b7>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(!ls)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.) Depth of Functional API"
      ],
      "metadata": {
        "id": "lk_fpkZSs6P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.layers import keras"
      ],
      "metadata": {
        "id": "9aEzvugKs6Yy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFjOdGZcwu7yGX9JBGH4Ew",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}